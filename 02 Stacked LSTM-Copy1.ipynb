{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "# %env CUDA_VISIBLE_DEVICES=\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Bidirectional, Dense\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.callbacks import History, TensorBoard\n",
    "\n",
    "from tools import load_household_power_consumption, augment\n",
    "from tools import to_timeseries\n",
    "from tools import split_train_test\n",
    "from tools import vis_evaluate\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from IPython.display import display\n",
    "from IPython.display import SVG, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "PREDICT_SIZE = 64\n",
    "BATCH_SIZE = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-22 16:02:16,590 [hybrid-lstm.tool | INFO] Load existing dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_x: (43642, 7)\n",
      "data_y: (43642, 1)\n",
      "train_x: (104459, 64, 7)\n",
      "train_y: (104459, 64, 1)\n",
      "test_x: (8589, 64, 7)\n",
      "test_y: (8589, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "dataset, data_x, data_y = load_household_power_consumption()\n",
    "train_x, train_y, test_x, test_y = split_train_test(data_x[:-PREDICT_SIZE], \n",
    "                                                    data_y[PREDICT_SIZE:], \n",
    "                                                    train_ratio=0.8)\n",
    "\n",
    "# Data Augmentation\n",
    "train_x = augment(train_x)\n",
    "train_y = augment(train_y)\n",
    "\n",
    "# Data Scaling\n",
    "scaler_x = MinMaxScaler((0, 1))\n",
    "scaler_y = MinMaxScaler((0, 1))\n",
    "\n",
    "scaler_x = scaler_x.fit(np.concatenate((train_x, test_x)))\n",
    "train_x = scaler_x.transform(train_x)\n",
    "test_x = scaler_x.transform(test_x)\n",
    "\n",
    "scaler_y = scaler_y.fit(np.concatenate((train_y, test_y)))\n",
    "train_y = scaler_y.transform(train_y)\n",
    "test_y = scaler_y.transform(test_y)\n",
    "\n",
    "# To Timeseries dataset\n",
    "train_x = to_timeseries(train_x, t=PREDICT_SIZE)\n",
    "train_y = to_timeseries(train_y, t=PREDICT_SIZE)\n",
    "test_x = to_timeseries(test_x, t=PREDICT_SIZE)\n",
    "test_y = to_timeseries(test_y, t=PREDICT_SIZE)\n",
    "\n",
    "print('data_x:', data_x.shape)\n",
    "print('data_y:', data_y.shape)\n",
    "print('train_x:', train_x.shape)\n",
    "print('train_y:', train_y.shape)\n",
    "print('test_x:', test_x.shape)\n",
    "print('test_y:', test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-22 16:10:01,237 [hybrid-lstm.tool | INFO] Load existing dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_x: (43642, 7)\n",
      "data_y: (43642, 1)\n",
      "train_x: (34760, 64, 7)\n",
      "train_y: (34760, 64, 1)\n",
      "test_x: (8691, 64, 7)\n",
      "test_y: (8691, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "dataset, data_x, data_y = load_household_power_consumption()\n",
    "\n",
    "data_x = MinMaxScaler().fit_transform(data_x)\n",
    "data_y = MinMaxScaler().fit_transform(data_y)\n",
    "\n",
    "train_x, train_y, test_x, test_y = split_train_test(to_timeseries(data_x[:-PREDICT_SIZE], t=PREDICT_SIZE), \n",
    "                                                    to_timeseries(data_y[PREDICT_SIZE:], t=PREDICT_SIZE), \n",
    "                                                    train_ratio=0.8)\n",
    "print('data_x:', data_x.shape)\n",
    "print('data_y:', data_y.shape)\n",
    "print('train_x:', train_x.shape)\n",
    "print('train_y:', train_y.shape)\n",
    "print('test_x:', test_x.shape)\n",
    "print('test_y:', test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"304pt\" viewBox=\"0.00 0.00 436.00 304.00\" width=\"436pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 300)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-300 432,-300 432,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139812659172352 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139812659172352</title>\n",
       "<polygon fill=\"none\" points=\"41.5,-249.5 41.5,-295.5 386.5,-295.5 386.5,-249.5 41.5,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"141.5\" y=\"-268.8\">bidirectional_1_input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"241.5,-249.5 241.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"269\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"241.5,-272.5 296.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"269\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"296.5,-249.5 296.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"341.5\" y=\"-280.3\">(None, 64, 7)</text>\n",
       "<polyline fill=\"none\" points=\"296.5,-272.5 386.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"341.5\" y=\"-257.3\">(None, 64, 7)</text>\n",
       "</g>\n",
       "<!-- 139812659171736 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139812659171736</title>\n",
       "<polygon fill=\"none\" points=\"-2.84217e-14,-166.5 -2.84217e-14,-212.5 428,-212.5 428,-166.5 -2.84217e-14,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"134.5\" y=\"-185.8\">bidirectional_1(lstm_1): Bidirectional(LSTM)</text>\n",
       "<polyline fill=\"none\" points=\"269,-166.5 269,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"296.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"269,-189.5 324,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"296.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"324,-166.5 324,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"376\" y=\"-197.3\">(None, 64, 7)</text>\n",
       "<polyline fill=\"none\" points=\"324,-189.5 428,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"376\" y=\"-174.3\">(None, 64, 256)</text>\n",
       "</g>\n",
       "<!-- 139812659172352&#45;&gt;139812659171736 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139812659172352-&gt;139812659171736</title>\n",
       "<path d=\"M214,-249.366C214,-241.152 214,-231.658 214,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"217.5,-222.607 214,-212.607 210.5,-222.607 217.5,-222.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139812654240264 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139812654240264</title>\n",
       "<polygon fill=\"none\" points=\"-2.84217e-14,-83.5 -2.84217e-14,-129.5 428,-129.5 428,-83.5 -2.84217e-14,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"134.5\" y=\"-102.8\">bidirectional_2(lstm_2): Bidirectional(LSTM)</text>\n",
       "<polyline fill=\"none\" points=\"269,-83.5 269,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"296.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"269,-106.5 324,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"296.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"324,-83.5 324,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"376\" y=\"-114.3\">(None, 64, 256)</text>\n",
       "<polyline fill=\"none\" points=\"324,-106.5 428,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"376\" y=\"-91.3\">(None, 64, 256)</text>\n",
       "</g>\n",
       "<!-- 139812659171736&#45;&gt;139812654240264 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139812659171736-&gt;139812654240264</title>\n",
       "<path d=\"M214,-166.366C214,-158.152 214,-148.658 214,-139.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"217.5,-139.607 214,-129.607 210.5,-139.607 217.5,-139.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139812654242896 -->\n",
       "<g class=\"node\" id=\"node4\"><title>139812654242896</title>\n",
       "<polygon fill=\"none\" points=\"83.5,-0.5 83.5,-46.5 344.5,-46.5 344.5,-0.5 83.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"134.5\" y=\"-19.8\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"185.5,-0.5 185.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"185.5,-23.5 240.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"240.5,-0.5 240.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292.5\" y=\"-31.3\">(None, 64, 256)</text>\n",
       "<polyline fill=\"none\" points=\"240.5,-23.5 344.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292.5\" y=\"-8.3\">(None, 64, 1)</text>\n",
       "</g>\n",
       "<!-- 139812654240264&#45;&gt;139812654242896 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>139812654240264-&gt;139812654242896</title>\n",
       "<path d=\"M214,-83.3664C214,-75.1516 214,-65.6579 214,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"217.5,-56.6068 214,-46.6068 210.5,-56.6069 217.5,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def r2(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred )) \n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "def create_model(l1=64, l2=64):\n",
    "    np.random.seed(0)\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(l1, return_sequences=True), input_shape=(PREDICT_SIZE, 7)))\n",
    "    model.add(Bidirectional(LSTM(l1, return_sequences=True)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy', r2])\n",
    "    return model\n",
    "\n",
    "model = create_model(128, 128)\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34760 samples, validate on 8691 samples\n",
      "Epoch 1/100\n",
      "11s - loss: 0.0186 - acc: 0.0000e+00 - r2: -7.7192e-01 - val_loss: 0.0102 - val_acc: 1.1506e-04 - val_r2: -9.1230e-02\n",
      "Epoch 2/100\n",
      "10s - loss: 0.0089 - acc: 0.0000e+00 - r2: 0.1506 - val_loss: 0.0082 - val_acc: 1.1506e-04 - val_r2: 0.1523\n",
      "Epoch 3/100\n"
     ]
    }
   ],
   "source": [
    "model = create_model(l1=128, l2=128)\n",
    "\n",
    "history = History()\n",
    "model.fit(train_x, train_y, epochs=100, batch_size=BATCH_SIZE, verbose=2, \n",
    "          validation_data=(test_x, test_y), callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34760 samples, validate on 8691 samples\n",
      "Epoch 1/100\n",
      "11s - loss: 0.0186 - acc: 0.0000e+00 - r2: -7.7192e-01 - val_loss: 0.0102 - val_acc: 1.1506e-04 - val_r2: -9.1230e-02\n",
      "Epoch 2/100\n",
      "9s - loss: 0.0089 - acc: 0.0000e+00 - r2: 0.1506 - val_loss: 0.0082 - val_acc: 1.1506e-04 - val_r2: 0.1523\n",
      "Epoch 3/100\n",
      "9s - loss: 0.0081 - acc: 0.0000e+00 - r2: 0.2286 - val_loss: 0.0083 - val_acc: 1.1506e-04 - val_r2: 0.1428\n",
      "Epoch 4/100\n",
      "9s - loss: 0.0079 - acc: 0.0000e+00 - r2: 0.2522 - val_loss: 0.0081 - val_acc: 1.1506e-04 - val_r2: 0.1696\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-396b3ebc6a29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHistory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m model.fit(train_x, train_y, epochs=100, batch_size=BATCH_SIZE, verbose=2, \n\u001b[0;32m----> 5\u001b[0;31m           validation_data=(test_x, test_y), callbacks=[history])\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1593\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1180\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2268\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2269\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2270\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2271\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = create_model(l1=128, l2=128)\n",
    "\n",
    "history = History()\n",
    "model.fit(train_x, train_y, epochs=100, batch_size=BATCH_SIZE, verbose=2, \n",
    "          validation_data=(test_x, test_y), callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%time eval_results = model.evaluate(test_x, test_y, batch_size=BATCH_SIZE, verbose=2)\n",
    "\n",
    "for k, v in zip(model.metrics_names, eval_results):\n",
    "    print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vis_evaluate(model, test_x, test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
